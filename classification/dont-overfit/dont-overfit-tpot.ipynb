{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tpot\n",
    "import pandas as pd\n",
    "from tpot import TPOTClassifier\n",
    "from benchmark_utils import timer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../datasets/dont-overfit/train.csv\")\n",
    "X_test = pd.read_csv(\"../datasets/dont-overfit/test.csv\")\n",
    "\n",
    "## Change target dtype\n",
    "y_train = pd.DataFrame(X_train.target,dtype='int')\n",
    "# Drop id and target from train frame\n",
    "X_train.drop(columns=['target','id'],inplace=True)\n",
    "## Copy test id's and drop id from test frame\n",
    "id_test = X_test.id\n",
    "X_test.drop(columns=['id'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>-2.246</td>\n",
       "      <td>1.825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>2.198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  ...  \\\n",
       "0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276 -2.246  1.825  ...   \n",
       "1  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  0.004 -0.291  ...   \n",
       "2 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  0.137  0.183  ...   \n",
       "3  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  0.503  0.274  ...   \n",
       "4  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509 -0.012  2.198  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3 -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=300, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.736\n",
      "Generation 2 - Current best internal CV score: 0.756\n",
      "Generation 3 - Current best internal CV score: 0.756\n",
      "Generation 4 - Current best internal CV score: 0.756\n",
      "Generation 5 - Current best internal CV score: 0.756\n",
      "\n",
      "Best pipeline: LogisticRegression(Normalizer(input_matrix, norm=l1), C=25.0, dual=False, penalty=l1)\n"
     ]
    }
   ],
   "source": [
    "start_time = timer(None)\n",
    "tp = TPOTClassifier(generations=5, population_size=50, random_state=42, verbosity=2)\n",
    "\n",
    "tp.fit(X_train, y_train)\n",
    "time = timer(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 1 0]\n",
      "\n",
      " Time taken: 0 hours 21 minutes and 45.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "tp.export('tpot_pipeline_dont_overfit.py')\n",
    "preds = tp.predict(X_test)\n",
    "print(preds)\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TPOTClassifier in module tpot.tpot object:\n",
      "\n",
      "class TPOTClassifier(tpot.base.TPOTBase)\n",
      " |  TPOTClassifier(generations=100, population_size=100, offspring_size=None, mutation_rate=0.9, crossover_rate=0.1, scoring=None, cv=5, subsample=1.0, n_jobs=1, max_time_mins=None, max_eval_time_mins=5, random_state=None, config_dict=None, template=None, warm_start=False, memory=None, use_dask=False, periodic_checkpoint_folder=None, early_stop=None, verbosity=0, disable_update_check=False)\n",
      " |  \n",
      " |  TPOT estimator for classification problems.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TPOTClassifier\n",
      " |      tpot.base.TPOTBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  classification = True\n",
      " |  \n",
      " |  default_config_dict = {'sklearn.cluster.FeatureAgglomeration': {'affin...\n",
      " |  \n",
      " |  regression = False\n",
      " |  \n",
      " |  scoring_function = 'accuracy'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tpot.base.TPOTBase:\n",
      " |  \n",
      " |  __init__(self, generations=100, population_size=100, offspring_size=None, mutation_rate=0.9, crossover_rate=0.1, scoring=None, cv=5, subsample=1.0, n_jobs=1, max_time_mins=None, max_eval_time_mins=5, random_state=None, config_dict=None, template=None, warm_start=False, memory=None, use_dask=False, periodic_checkpoint_folder=None, early_stop=None, verbosity=0, disable_update_check=False)\n",
      " |      Set up the genetic programming algorithm for pipeline optimization.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      generations: int, optional (default: 100)\n",
      " |          Number of iterations to the run pipeline optimization process.\n",
      " |          Generally, TPOT will work better when you give it more generations (and\n",
      " |          therefore time) to optimize the pipeline. TPOT will evaluate\n",
      " |          POPULATION_SIZE + GENERATIONS x OFFSPRING_SIZE pipelines in total.\n",
      " |      population_size: int, optional (default: 100)\n",
      " |          Number of individuals to retain in the GP population every generation.\n",
      " |          Generally, TPOT will work better when you give it more individuals\n",
      " |          (and therefore time) to optimize the pipeline. TPOT will evaluate\n",
      " |          POPULATION_SIZE + GENERATIONS x OFFSPRING_SIZE pipelines in total.\n",
      " |      offspring_size: int, optional (default: None)\n",
      " |          Number of offspring to produce in each GP generation.\n",
      " |          By default, offspring_size = population_size.\n",
      " |      mutation_rate: float, optional (default: 0.9)\n",
      " |          Mutation rate for the genetic programming algorithm in the range [0.0, 1.0].\n",
      " |          This parameter tells the GP algorithm how many pipelines to apply random\n",
      " |          changes to every generation. We recommend using the default parameter unless\n",
      " |          you understand how the mutation rate affects GP algorithms.\n",
      " |      crossover_rate: float, optional (default: 0.1)\n",
      " |          Crossover rate for the genetic programming algorithm in the range [0.0, 1.0].\n",
      " |          This parameter tells the genetic programming algorithm how many pipelines to\n",
      " |          \"breed\" every generation. We recommend using the default parameter unless you\n",
      " |          understand how the mutation rate affects GP algorithms.\n",
      " |      scoring: string or callable, optional\n",
      " |          Function used to evaluate the quality of a given pipeline for the\n",
      " |          problem. By default, accuracy is used for classification problems and\n",
      " |          mean squared error (MSE) for regression problems.\n",
      " |      \n",
      " |          Offers the same options as sklearn.model_selection.cross_val_score as well as\n",
      " |          a built-in score 'balanced_accuracy'. Classification metrics:\n",
      " |      \n",
      " |          ['accuracy', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy',\n",
      " |          'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted',\n",
      " |          'precision', 'precision_macro', 'precision_micro', 'precision_samples',\n",
      " |          'precision_weighted', 'recall', 'recall_macro', 'recall_micro',\n",
      " |          'recall_samples', 'recall_weighted', 'roc_auc']\n",
      " |      \n",
      " |          Regression metrics:\n",
      " |      \n",
      " |          ['neg_median_absolute_error', 'neg_mean_absolute_error',\n",
      " |          'neg_mean_squared_error', 'r2']\n",
      " |      \n",
      " |          If you would like to use a custom scoring function, you can pass a callable\n",
      " |          function to this parameter with the signature scorer(y_true, y_pred).\n",
      " |          See the section on scoring functions in the documentation for more details.\n",
      " |      \n",
      " |          TPOT assumes that any custom scoring function with \"error\" or \"loss\" in the\n",
      " |          name is meant to be minimized, whereas any other functions will be maximized.\n",
      " |      cv: int or cross-validation generator, optional (default: 5)\n",
      " |          If CV is a number, then it is the number of folds to evaluate each\n",
      " |          pipeline over in k-fold cross-validation during the TPOT optimization\n",
      " |           process. If it is an object then it is an object to be used as a\n",
      " |           cross-validation generator.\n",
      " |      subsample: float, optional (default: 1.0)\n",
      " |          Subsample ratio of the training instance. Setting it to 0.5 means that TPOT\n",
      " |          randomly collects half of training samples for pipeline optimization process.\n",
      " |      n_jobs: int, optional (default: 1)\n",
      " |          Number of CPUs for evaluating pipelines in parallel during the TPOT\n",
      " |          optimization process. Assigning this to -1 will use as many cores as available\n",
      " |          on the computer. For n_jobs below -1, (n_cpus + 1 + n_jobs) are used.\n",
      " |          Thus for n_jobs = -2, all CPUs but one are used.\n",
      " |      max_time_mins: int, optional (default: None)\n",
      " |          How many minutes TPOT has to optimize the pipeline.\n",
      " |          If provided, this setting will override the \"generations\" parameter and allow\n",
      " |          TPOT to run until it runs out of time.\n",
      " |      max_eval_time_mins: float, optional (default: 5)\n",
      " |          How many minutes TPOT has to optimize a single pipeline.\n",
      " |          Setting this parameter to higher values will allow TPOT to explore more\n",
      " |          complex pipelines, but will also allow TPOT to run longer.\n",
      " |      random_state: int, optional (default: None)\n",
      " |          Random number generator seed for TPOT. Use this parameter to make sure\n",
      " |          that TPOT will give you the same results each time you run it against the\n",
      " |          same data set with that seed.\n",
      " |      config_dict: a Python dictionary or string, optional (default: None)\n",
      " |          Python dictionary:\n",
      " |              A dictionary customizing the operators and parameters that\n",
      " |              TPOT uses in the optimization process.\n",
      " |              For examples, see config_regressor.py and config_classifier.py\n",
      " |          Path for configuration file:\n",
      " |              A path to a configuration file for customizing the operators and parameters that\n",
      " |              TPOT uses in the optimization process.\n",
      " |              For examples, see config_regressor.py and config_classifier.py\n",
      " |          String 'TPOT light':\n",
      " |              TPOT uses a light version of operator configuration dictionary instead of\n",
      " |              the default one.\n",
      " |          String 'TPOT MDR':\n",
      " |              TPOT uses a list of TPOT-MDR operator configuration dictionary instead of\n",
      " |              the default one.\n",
      " |          String 'TPOT sparse':\n",
      " |              TPOT uses a configuration dictionary with a one-hot-encoder and the\n",
      " |              operators normally included in TPOT that also support sparse matrices.\n",
      " |      template: string (default: None)\n",
      " |          Template of predefined pipeline structure. The option is for specifying a desired structure\n",
      " |          for the machine learning pipeline evaluated in TPOT. So far this option only supports\n",
      " |          linear pipeline structure. Each step in the pipeline should be a main class of operators\n",
      " |          (Selector, Transformer, Classifier or Regressor) or a specific operator\n",
      " |          (e.g. SelectPercentile) defined in TPOT operator configuration. If one step is a main class,\n",
      " |          TPOT will randomly assign all subclass operators (subclasses of SelectorMixin,\n",
      " |          TransformerMixin, ClassifierMixin or RegressorMixin in scikit-learn) to that step.\n",
      " |          Steps in the template are delimited by \"-\", e.g. \"SelectPercentile-Transformer-Classifier\".\n",
      " |          By default value of template is None, TPOT generates tree-based pipeline randomly.\n",
      " |      warm_start: bool, optional (default: False)\n",
      " |          Flag indicating whether the TPOT instance will reuse the population from\n",
      " |          previous calls to fit().\n",
      " |      memory: a Memory object or string, optional (default: None)\n",
      " |          If supplied, pipeline will cache each transformer after calling fit. This feature\n",
      " |          is used to avoid computing the fit transformers within a pipeline if the parameters\n",
      " |          and input data are identical with another fitted pipeline during optimization process.\n",
      " |          String 'auto':\n",
      " |              TPOT uses memory caching with a temporary directory and cleans it up upon shutdown.\n",
      " |          String path of a caching directory\n",
      " |              TPOT uses memory caching with the provided directory and TPOT does NOT clean\n",
      " |              the caching directory up upon shutdown. If the directory does not exist, TPOT will\n",
      " |              create it.\n",
      " |          Memory object:\n",
      " |              TPOT uses the instance of joblib.Memory for memory caching,\n",
      " |              and TPOT does NOT clean the caching directory up upon shutdown.\n",
      " |          None:\n",
      " |              TPOT does not use memory caching.\n",
      " |      use_dask: boolean, default False\n",
      " |          Whether to use Dask-ML's pipeline optimiziations. This avoid re-fitting\n",
      " |          the same estimator on the same split of data multiple times. It\n",
      " |          will also provide more detailed diagnostics when using Dask's\n",
      " |          distributed scheduler.\n",
      " |      \n",
      " |          See `avoid repeated work <https://dask-ml.readthedocs.io/en/latest/hyper-parameter-search.html#avoid-repeated-work>`__\n",
      " |          for more details.\n",
      " |      periodic_checkpoint_folder: path string, optional (default: None)\n",
      " |          If supplied, a folder in which tpot will periodically save pipelines in pareto front so far while optimizing.\n",
      " |          Currently once per generation but not more often than once per 30 seconds.\n",
      " |          Useful in multiple cases:\n",
      " |              Sudden death before tpot could save optimized pipeline\n",
      " |              Track its progress\n",
      " |              Grab pipelines while it's still optimizing\n",
      " |      early_stop: int or None (default: None)\n",
      " |          How many generations TPOT checks whether there is no improvement in optimization process.\n",
      " |          End optimization process if there is no improvement in the set number of generations.\n",
      " |      verbosity: int, optional (default: 0)\n",
      " |          How much information TPOT communicates while it's running.\n",
      " |          0 = none, 1 = minimal, 2 = high, 3 = all.\n",
      " |          A setting of 2 or higher will add a progress bar during the optimization procedure.\n",
      " |      disable_update_check: bool, optional (default: False)\n",
      " |          Flag indicating whether the TPOT version checker should be disabled.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |  \n",
      " |  clean_pipeline_string(self, individual)\n",
      " |      Provide a string of the individual without the parameter prefixes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      individual: individual\n",
      " |          Individual which should be represented by a pretty string\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A string like str(individual), but with parameter prefixes removed.\n",
      " |  \n",
      " |  export(self, output_file_name, data_file_path='')\n",
      " |      Export the optimized pipeline as Python code.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      output_file_name: string\n",
      " |          String containing the path and file name of the desired output file\n",
      " |      data_file_path: string (default: '')\n",
      " |          By default, the path of input dataset is 'PATH/TO/DATA/FILE' by default.\n",
      " |          If data_file_path is another string, the path will be replaced.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      False if it skipped writing the pipeline to file\n",
      " |      True if the pipeline was actually written\n",
      " |  \n",
      " |  fit(self, features, target, sample_weight=None, groups=None)\n",
      " |      Fit an optimized machine learning pipeline.\n",
      " |      \n",
      " |      Uses genetic programming to optimize a machine learning pipeline that\n",
      " |      maximizes score on the provided features and target. Performs internal\n",
      " |      k-fold cross-validaton to avoid overfitting on the provided data. The\n",
      " |      best pipeline is then trained on the entire set of provided samples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      features: array-like {n_samples, n_features}\n",
      " |          Feature matrix\n",
      " |      \n",
      " |          TPOT and all scikit-learn algorithms assume that the features will be numerical\n",
      " |          and there will be no missing values. As such, when a feature matrix is provided\n",
      " |          to TPOT, all missing values will automatically be replaced (i.e., imputed) using\n",
      " |          median value imputation.\n",
      " |      \n",
      " |          If you wish to use a different imputation strategy than median imputation, please\n",
      " |          make sure to apply imputation to your feature set prior to passing it to TPOT.\n",
      " |      target: array-like {n_samples}\n",
      " |          List of class labels for prediction\n",
      " |      sample_weight: array-like {n_samples}, optional\n",
      " |          Per-sample weights. Higher weights indicate more importance. If specified,\n",
      " |          sample_weight will be passed to any pipeline element whose fit() function accepts\n",
      " |          a sample_weight argument. By default, using sample_weight does not affect tpot's\n",
      " |          scoring functions, which determine preferences between pipelines.\n",
      " |      groups: array-like, with shape {n_samples, }, optional\n",
      " |          Group labels for the samples used when performing cross-validation.\n",
      " |          This parameter should only be used in conjunction with sklearn's Group cross-validation\n",
      " |          functions, such as sklearn.model_selection.GroupKFold\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self: object\n",
      " |          Returns a copy of the fitted TPOT object\n",
      " |  \n",
      " |  fit_predict(self, features, target, sample_weight=None, groups=None)\n",
      " |      Call fit and predict in sequence.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      features: array-like {n_samples, n_features}\n",
      " |          Feature matrix\n",
      " |      target: array-like {n_samples}\n",
      " |          List of class labels for prediction\n",
      " |      sample_weight: array-like {n_samples}, optional\n",
      " |          Per-sample weights. Higher weights force TPOT to put more emphasis on those points\n",
      " |      groups: array-like, with shape {n_samples, }, optional\n",
      " |          Group labels for the samples used when performing cross-validation.\n",
      " |          This parameter should only be used in conjunction with sklearn's Group cross-validation\n",
      " |          functions, such as sklearn.model_selection.GroupKFold\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      array-like: {n_samples}\n",
      " |          Predicted target for the provided features\n",
      " |  \n",
      " |  predict(self, features)\n",
      " |      Use the optimized pipeline to predict the target for a feature set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      features: array-like {n_samples, n_features}\n",
      " |          Feature matrix\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      array-like: {n_samples}\n",
      " |          Predicted target for the samples in the feature matrix\n",
      " |  \n",
      " |  predict_proba(self, features)\n",
      " |      Use the optimized pipeline to estimate the class probabilities for a feature set.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      features: array-like {n_samples, n_features}\n",
      " |          Feature matrix of the testing set\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array-like: {n_samples, n_target}\n",
      " |          The class probabilities of the input samples\n",
      " |  \n",
      " |  score(self, testing_features, testing_target)\n",
      " |      Return the score on the given testing data using the user-specified scoring function.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      testing_features: array-like {n_samples, n_features}\n",
      " |          Feature matrix of the testing set\n",
      " |      testing_target: array-like {n_samples}\n",
      " |          List of class labels for prediction in the testing set\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      accuracy_score: float\n",
      " |          The estimated test set accuracy\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = [0.736,\n",
    "0.74,\n",
    "0.76,\n",
    "0.76,\n",
    "0.764,\n",
    "0.764,\n",
    "0.764,\n",
    "0.764,\n",
    "0.764,\n",
    "0.768,\n",
    "0.768,\n",
    "0.768,\n",
    "0.768,\n",
    "0.768,\n",
    "0.768,\n",
    "0.764,\n",
    "0.764,\n",
    "0.764,\n",
    "0.764,\n",
    "0.784,\n",
    "0.784,\n",
    "0.784,\n",
    "0.784,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "0.792,\n",
    "]\n",
    "\n",
    "generations = [i for i in range(1,51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 3.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from seaborn) (1.16.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from seaborn) (0.25.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from seaborn) (1.2.0)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from seaborn) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2019.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from pandas>=0.15.2->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/midas/anaconda3/envs/automl-3.7/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.0.1)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.lineplot(x=generations, y=train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Time taken: 0 hours 21 minutes and 45.49 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8657939809150967\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "preds_train = tp.predict(X_train)\n",
    "\n",
    "print(\"Accuracy score\", metrics.roc_auc_score(preds_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"id\": id_test,\n",
    "        \"target\": preds\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"../submit_files/dont_overfit_tpot_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
